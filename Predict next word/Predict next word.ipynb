{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using Alice in wonderland book\n",
    "text = gutenberg.raw(fileids='carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_grams_model(text):\n",
    "    \"\"\" the function takes the text as an input & returns bigrams\"\"\"\n",
    "    # tokenise text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # create bi_gram list\n",
    "    bi_grams = list(ngrams(words, 2))\n",
    "    return bi_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(text):\n",
    "    \"\"\"the function creates a dataframe from bi_gram model\"\"\"\n",
    "    #text = normalise(text)\n",
    "    bi_grams = bi_grams_model(text) \n",
    "    \n",
    "    # create from a bi_gram list a dictionary where each word is the key and its value is the words that are coming after them\n",
    "    # collections.defaultdict: group a sequence of key-value pairs into a dictionary of lists\n",
    "    dict_bi_grams = collections.defaultdict(list)\n",
    "    for key, value in bi_grams:\n",
    "        dict_bi_grams[key].append(value)\n",
    "        \n",
    "    # get the frequency that word(i-1) & word(i) occur together\n",
    "    dict_freq = {}\n",
    "    for key in dict_bi_grams:\n",
    "        val = dict_bi_grams[key]\n",
    "        dict_freq[key] = collections.Counter(val)\n",
    "    dict_freq\n",
    "    \n",
    "    # get word counts\n",
    "    word_counts = pd.Series(collections.Counter(nltk.word_tokenize(text)))\n",
    "    \n",
    "    # create dataframe from frequency dictionary, where index and columns are all words in the text\n",
    "    df = pd.DataFrame.from_dict(dict_freq, orient='index')\n",
    "    # Normalise by unigram (dividing by the whole count of each word)\n",
    "    df = df.div(word_counts, axis=0)\n",
    "    # replace Nan values with zeros\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    \"\"\" the function gives prediction to the next word.\n",
    "        if the word not in the lyrics, it'll give a message saying 'Word not found'\n",
    "    \"\"\"\n",
    "    df = frequency(text)\n",
    "    if word not in df.index:\n",
    "        print('Word not found')\n",
    "    else:\n",
    "        x = df.loc[word, :]\n",
    "        prediction = x[x!=0].to_dict()\n",
    "        words = list(prediction.keys())\n",
    "        probability = list(prediction.values())\n",
    "        predicted = words[probability.index(max(probability))]\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let's see which words come after Alice as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",          0.197970\n",
       ".          0.137056\n",
       "was        0.043147\n",
       ";          0.040609\n",
       "thought    0.030457\n",
       "could      0.027919\n",
       "had        0.027919\n",
       "said       0.027919\n",
       "did        0.025381\n",
       "'s         0.022843\n",
       "Name: Alice, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = frequency(text)\n",
    "df.loc['Alice'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the shape of dataframe and unique words in the story\n",
    "they should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3185, 3185)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(frequency(text)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3185"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(nltk.word_tokenize(text))\n",
    "len(np.unique(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
